#!/usr/bin/perl
use strict;
use warnings;
use bigint;
use Find::Lib qw(../lib);
use LogZilla::DebugFilter;
use Log::Fast;
use FindBin;
use LogZilla::Config;
use Getopt::Long;
use File::Basename;
use Cwd qw(abs_path);
use DBI;
use DBD::mysql;
my $ROOT_DIR = abs_path("$FindBin::Bin/..");
use Date::Simple ( 'date', 'today' );
use Date::Parse;
use Date::Format;
use List::Util qw(sum);

#FIXME - I had to add below for Perl 5.10 users.
# on Perl 5.10, I would get the following when running:
# perl -e"autoflush STDOUT, 1;"
# Can't locate object method "autoflush" via package "IO::Handle" at -e line 1.
use FileHandle;

# Create default logger, will reconfigure it as soon as we read configuration from database
my $log = Log::Fast->global();

my (@runfuncs);
my $dbh_sphinx;
my @functionlist = ( "countUpdate", "updateHosts", "tblSync", "cleanup_old_views", "cleanup_old_idx", "ss", "idx_rotate", "mtti", "mvdate" );

# Command line options
my $options = {
    debug    => 0,
    verbose  => 0,
    log_file => undef,    # will set default later based on settings in DB
    config_file => "$ROOT_DIR/html/config/config.php",
    help        => 0,
};

sub usage_and_exit {
    my ($exit_code) = @_;

    my $myname = $0;
    $myname =~ s{.*/}{};    # leave just program name without path

    # TODO sync this with getopt
    print STDERR qq{
This program is used to process incoming syslog messages from a file.
Usage: $myname [-option -option] 
    -h        : this (help) message
    -d        : debug level (0-5) (0 = disabled [default])
    -dr       : Dry Run (don't make any changes)
    -v        : Also print results to STDERR
    -l        : log file (defaults to dir set in DB settings)
    -r        : Run only specified function(s) (used for debugging)
    -f        : list available functions (for debug use)
    -ss       : Analyze Server Stats [option -mysql]
    -mvdate   : Used with 'makeview' function to recreate views for old data imports
    -c        : config file (defaults to $options->{config_file})
Example: $myname -l /var/log/foo.log -d 5 -c test/config.php -v
};
    exit($exit_code);
}

GetOptions(
    'debug|d=i'       => \$options->{debug},
    'dryrun|dr'       => \$options->{dryrun},
    'help|h!'         => \$options->{help},
    'verbose|v!'      => \$options->{verbose},
    'log-file|l=s'    => \$options->{log_file},
    'config-file|c=s' => \$options->{config_file},
    'runfuncs|r=s'    => \@runfuncs,
    'functionlist|f!' => \$options->{functionlist},
    'idx_rotate!'     => \$options->{idx_rotate},
    'mtti!'           => \$options->{mtti},
    'mysql!'          => \$options->{mysql},
    'mvdate|mvd=s'    => \$options->{mvdate},
    'yes|y'           => \$options->{yes},
) or usage_and_exit(1);    # got some invalid options

if ( $options->{help} ) {
    usage_and_exit(0);
}

# Read configuration from (PHP) config file
my $cfg = LogZilla::Config->new( path => $options->{config_file} );

# Connect to DB and setup error handler to log to $log and then exit with error
my $dbh = connect_to_db();

# Read settings from DB.
my $settings = read_settings_from_db();
my ( $lzmajor, $lzminor ) = split( /\./, $settings->{VERSION} );
my ( undef,    $lzsub )   = split( /\./, $settings->{VERSION_SUB} );
DEBUG( 1, "LogZilla Version Check: $lzmajor, $lzminor, $lzsub" );

# Reconfigure log to use log_file (as we finally got it from $settings), also
# set proper level and output based on $options{verbose} and $options{debug}
setup_log();

if ( $options->{dryrun} ) {
    $log->INFO("Dry Run Mode - No modifications will be made");
}

# Finally we are initialized, announce this to the world :-)
$log->INFO("Program initialized successfully");

my ( $results, $rc, $sth_syslog, $sth_sphinx, $sql );
my bigint $count;

# calcualating yesterday

my ( $yWeekday, $yYear, $yMonth, $yDay ) = ( localtime( time - 24 * 60 * 60 ) )[ 6, 5, 4, 3 ];
$yYear += 1900;
$yMonth++;

# use 2 digit months and days

$yMonth = sprintf "%02d", $yMonth;
$yDay   = sprintf "%02d", $yDay;

# so the sphinx view of yesterdays data is
my @DoW = qw( Sun Mon Tue Wed Fri Sat );

my $sphinx_yesterday = 'idx_log_arch_day_' . $yYear . $yMonth . $yDay;

if ( defined( $options->{functionlist} ) ) {
    $log->INFO("Available Functions:");
    foreach my $func (@functionlist) {
        $log->INFO("$func");
    }
    exit;
}
if ( $#runfuncs < 0 ) {
    waitfor( "indexer", 5, 300 );
    $dbh_sphinx = DBI->connect( 'DBI:mysql::127.0.0.1:9306', 'root', ) || die "Could not connect to SphinxQL: $DBI::errstr";
    countUpdate();
    updateHosts();
    tblSync( "mne",       "mne" );
    tblSync( "snare_eid", "eid" );
    tblSync( "programs",  "program" );
    cleanup_old_views();
    cleanup_old_idx();

#idx_rotate(); we need to run this separately - calling it during the nightly cron will lock all other procs until it completes.
    mtti();
} else {
    $log->INFO("Running specific functions only");
    waitfor( "indexer", 5, 300 );
    $dbh_sphinx = DBI->connect( 'DBI:mysql::127.0.0.1:9306', 'root', ) || die "Could not connect to SphinxQL: $DBI::errstr";

    foreach my $func (@runfuncs) {
        DEBUG( 1, "Starting $func" );
        if ( $func eq "countUpdate" ) {
            countUpdate();
        }
        elsif ( $func eq "updateHosts" ) {
            updateHosts();
        }
        elsif ( $func eq "tblSync" ) {
            tblSync( "mne",       "mne" );
            tblSync( "snare_eid", "eid" );
            tblSync( "programs",  "program" );
        }
        elsif ( $func eq "cleanup_old_views" ) {
            cleanup_old_views();
        }
        elsif ( $func eq "cleanup_old_idx" ) {
            cleanup_old_idx();
        }
        elsif ( $func eq "ss" ) {
            ss();
        }
        elsif ( $func eq "idx_rotate" ) {
            idx_rotate();
        }
        elsif ( $func eq "mtti" ) {
            mtti();
        }
        elsif ( $func eq "makeview" ) {
            makeview();
        }
        DEBUG( 1, "Ending $func" );
    }
}

# There should only be subs from here down

sub getYN {
    my ( $prompt, $default ) = @_;
    my $defaultValue = $default ? "[$default]" : "";
    print "$prompt $defaultValue: ";
    chomp( my $input = <STDIN> );
    return $input ? $input : $default;
}

sub tblSync {
    my $db_tbl  = shift;
    my $spx_tbl = shift;
    $log->INFO("Syncing DB->$db_tbl to SP->$spx_tbl...");
    $sql = "update $db_tbl set seen=0, hidden='true'";
    DEBUG( 1, "Executing SQL Statement: $sql" );
    $dbh->do($sql) unless $options->{dryrun};

    if ( $lzminor > 4 ) {
        $sql = "SELECT $spx_tbl, sum(counter), max(lo) from idx_all where match('\@dummy dummy') group by $spx_tbl limit 50000 OPTION max_matches=5000";
    } else {
        $sql = "SELECT $spx_tbl, sum(counter), max(lo) from distributed group by $spx_tbl limit 50000 OPTION max_matches=5000";
    }
    $sth_sphinx = $dbh_sphinx->prepare($sql);
    DEBUG( 1, "Executing SQL Statement: $sql" );
    $sth_sphinx->execute();
    if ( $sth_sphinx->rows > 0 ) {
        $log->INFO( "Found %d ${spx_tbl}s", $sth_sphinx->rows );
        while ( $results = $sth_sphinx->fetchrow_hashref ) {
            $sql = "";
            if ( $db_tbl eq "snare_eid" ) {
                $sql = "update $db_tbl set seen='" . $results->{'sum(counter)'} . "', lastseen=GREATEST(lastseen,from_unixtime('" . $results->{'max(lo)'} . "')), hidden='false' where eid='" . $results->{"$spx_tbl"} . "'";
            } else {
                $sql = "update $db_tbl set seen='" . $results->{'sum(counter)'} . "', lastseen=GREATEST(lastseen,from_unixtime('" . $results->{'max(lo)'} . "')), hidden='false' where crc='" . $results->{"$spx_tbl"} . "'";
            }
            DEBUG( 1, "Executing SQL Statement: $sql" );
            $dbh->do($sql) unless $options->{dryrun};
        }
    }
}

sub cleanup_old_views {

    # cleanup old search results
    my $ts;
    $rc = 'drop view ';
    $sql = "SELECT table_name from information_schema.views where table_name like '%search_results'";
    $sth_syslog = $dbh->prepare($sql);
    DEBUG( 1, "Executing SQL Statement: $sql" );
    $sth_syslog->execute();
    while ( $results = $sth_syslog->fetchrow_hashref ) {
        # cdukes: #466 - Added TS check for expired view names 
        DEBUG(1, "Checking expire date on %s", $results->{'table_name'});
        ( $ts ) = split( /_/, $results->{'table_name'} );
        DEBUG(1, "View TS = %d, Current TS = %d", $ts, time());
        if ($ts <= time()) { 
            $rc = $rc . $results->{'table_name'};
            $rc = $rc . ",";
        } else {
            DEBUG(1, "%s has not expired, keeping view", $results->{'table_name'});
        }
    }
    $rc = substr( $rc, 0, -1 );
    if ( $rc !~ /^drop view$/ ) {
        DEBUG( 1, "Executing SQL Statement: '$rc'" );
        $dbh->do($rc) unless $options->{dryrun};
    }
}

sub countUpdate {
    $log->INFO("Collecting Counts");

    # Preparing replacement for updateCache db procedure: Count all counters
    # due to a bug in sphinxql when using sum you also need to use a group-by
    if ( $lzminor > 4 ) {
        $sql = "SELECT severity, sum(counter) from idx_all where match('\@dummy dummy') group by severity limit 50000 OPTION max_matches=5000";
    } else {
        $sql = "SELECT severity, sum(counter) from distributed group by severity limit 50000 OPTION max_matches=5000";
    }
    DEBUG( 1, "Preparing SQL Statement: $sql" );
    $sth_sphinx = $dbh_sphinx->prepare($sql);
    $sth_sphinx->execute();
    $count = 0;

    # Print number of rows found
    if ( $sth_sphinx->rows == 0 ) {
        $log->INFO("No data found, do you have any log data?");
        exit;
    } else {
        $log->INFO( "Verifying msg_sum cache", $sth_sphinx->rows );
        my $spx_total = $dbh_sphinx->do('SELECT * from idx_all WHERE MATCH(\'@dummy dummy\') limit 1');
        my $spx_meta  = $dbh_sphinx->prepare('show meta');
        $spx_meta->execute();
        while ( $results = $spx_meta->fetchrow_hashref ) {
            if ( $results->{'Variable_name'} eq "total_found" ) {
                $log->INFO("There are %s indexed events", commify( $results->{'Value'} ));
	        $count = $results->{'Value'};
                $sth_syslog = $dbh->prepare('REPLACE INTO cache (name,value,updatetime) VALUES ("msg_sum",?,NOW());');
                $sth_syslog->execute($count) unless $options->{dryrun};
                store_metric( "lztool_msgsum", $count );
            }
        }

    }

    # Check yesterday's counters
    $sql = "show tables like '$sphinx_yesterday'";
    DEBUG( 1, "Preparing SQL Statement: $sql" );
    $sth_syslog = $dbh->prepare($sql);
    $sth_syslog->execute();
    if ( $sth_syslog->rows == 0 ) {
        DEBUG( 1, "No index for $sphinx_yesterday, no need to update counts..." );
    } else {
        if ( $lzminor > 4 ) {
            $sql = "SELECT severity, sum(counter) from $sphinx_yesterday where match('\@dummy dummy') group by severity";
        } else {
            $sql = "SELECT severity, sum(counter) from $sphinx_yesterday group by severity";
        }
        DEBUG( 1, "Preparing SQL Statement: $sql" );
        $sth_sphinx = $dbh_sphinx->prepare($sql);
        $sth_sphinx->execute();
        $count = 0;
        while ( $results = $sth_sphinx->fetchrow_hashref ) {
            $count = $count + $results->{'sum(counter)'};
        }
        if ( $count > 0 ) {
            my $cache_yesterday_statistics = 'chart_mpd_' . $yYear . "-" . $yMonth . "-" . $yDay . "_" . $DoW[$yWeekday];
            $log->INFO("Updating $cache_yesterday_statistics with $count");
            $sql = "REPLACE INTO cache (name,value,updatetime) VALUES ('$cache_yesterday_statistics',$count,NOW())";
            DEBUG( 1, "Executing SQL Statement: $sql" );
            $dbh->do($sql) unless $options->{dryrun};
        }
    }
}

sub updateHosts {
    my $table = shift;
    $sql = "update hosts set seen=0, hidden='true'";
    DEBUG( 1, "Executing SQL Statement: $sql" );
    $dbh->do($sql) unless $options->{dryrun};

# Note that DB's with host count > 5000 may be a problem here. This needs testing.
    if ( $lzminor > 4 ) {
        $sql = "SELECT host_crc, sum(counter), max(lo) from idx_all where match('\@dummy dummy') group by host_crc limit 50000 OPTION max_matches=5000";
    } else {
        $sql = "SELECT host_crc, sum(counter), max(lo) from distributed group by host_crc limit 50000 OPTION max_matches=5000";
    }
    DEBUG( 1, "Executing SQL Statement: $sql" );
    $dbh_sphinx->do($sql);
    my $sth_sphinx = $dbh_sphinx->prepare($sql);
    $sth_sphinx->execute();
    if ( $sth_sphinx->rows > 0 ) {
        $log->INFO( "Updating %d hosts...", $sth_sphinx->rows );
        store_metric( "lztool_hostcount", sprintf( "%d", $sth_sphinx->rows ) );
        while ( my $results = $sth_sphinx->fetchrow_hashref ) {
            $sql = ( "update hosts set seen=" . $results->{'sum(counter)'} . ", lastseen=GREATEST(lastseen,from_unixtime(" . $results->{'max(lo)'} . ")), hidden='false' where crc32(host)=" . $results->{'host_crc'} );
            DEBUG( 1, "Executing SQL Statement: $sql" );
            $dbh->do($sql) unless $options->{dryrun};
        }
        $log->INFO("Searching for dropped hosts...");
        $sql = "SELECT value from settings WHERE name='RETENTION_DROPS_HOSTS'";
        $sth_syslog = $dbh->prepare($sql);
        DEBUG( 1, "Executing SQL Statement: $sql" );
        $sth_syslog->execute();
        if ( ( $sth_sphinx->rows ) < 0 ) {
            $log->ERROR("RETENTION_DROPS_HOST not found in SETTINGS");
        } else {
            $results = $sth_syslog->fetchrow_hashref;
            if ( ( $results->{'value'} ) == 1 ) {
                $log->INFO("RETENTION_DROPS_HOST found. Dropping hidden hosts");
                $sql = "delete from hosts where hidden='true'";
                DEBUG( 1, "Executing SQL Statement: $sql" );
                $dbh->do($sql) unless $options->{dryrun};
            }
        }
    }
}

$sth_sphinx->finish if defined( ($sth_sphinx) );
$sth_syslog->finish if defined( ($sth_syslog) );
$dbh_sphinx->disconnect();
$dbh->disconnect();

# =================================================================================================
# Helper functions
# =================================================================================================

sub humanBytes {
    my $size = shift;
    $size = $size * 1024;    # incoming numbers are in kilobytes already
    if ( $size > 1099511627776 )    #   TiB: 1024 GiB
    {
        return sprintf( "%.2f TiB", $size / 1099511627776 );
    }
    elsif ( $size > 1073741824 )    #   GiB: 1024 MiB
    {
        return sprintf( "%.2f GiB", $size / 1073741824 );
    }
    elsif ( $size > 1048576 )       #   MiB: 1024 KiB
    {
        return sprintf( "%.2f MiB", $size / 1048576 );
    }
    elsif ( $size > 1024 )          #   KiB: 1024 B
    {
        return sprintf( "%.2f KiB", $size / 1024 );
    }
    else                            #   bytes
    {
        return "$size byte" . ( $size == 1 ? "" : "s" );
    }
}

sub humanReadable {
    my $i = shift;
    $i = $i * 1000;
    if ( $i > 1000000000000 )       #   TB: 1000 GB
    {
        return sprintf( "%.0f T", $i / 1000000000000 );
    }
    elsif ( $i > 1073741824 )       #   GB: 1000 MB
    {
        return sprintf( "%.0f B", $i / 1000000000 );
    }
    elsif ( $i > 1048576 )          #   MB: 1000 KB
    {
        return sprintf( "%.0f M", $i / 1000000 );
    }
    elsif ( $i > 1000 )             #   KB: 1000 B
    {
        return sprintf( "%.0f K", $i / 1000 );
    }
    else                            #   bytes
    {
        return "$i byte" . ( $i == 1 ? "" : "s" );
    }
}

sub HumanToBytes {
    my @strings = @_;
    my $base    = 1024;
    my %units   = (
        K => $base,
        M => $base**2,
        G => $base**3,
        T => $base**4,
        P => $base**5,
        E => $base**6,
        Z => $base**7,
        Y => $base**8,
    );
    my $pattern = join( '|', sort keys %units );
    my $total;
    for my $string (@strings) {
        while ( $string =~ /(([0-9]*(?:\.[0-9]+)?)($pattern))/g ) {
            my $number = $2 * $units{$3};
            $total += $number;
            DEBUG( 1, "Converting %12s to %12.0f", $1, $number );
        }
    }
    return sprintf "%.0f", $total;
}

sub commify {
    my $text = reverse $_[0];
    $text =~ s/(\d\d\d)(?=\d)(?!\d*\.)/$1,/g;
    return scalar reverse $text;
}

sub mean {
    return @_ ? sum(@_) / @_ : 0
}

sub sec2human {
    my $secs = shift;
    if ( $secs >= 365 * 24 * 60 * 60 ) { return sprintf '%.1f Years', $secs / ( 365 * 24 * 60 * 60 ) }
    elsif ( $secs >= 24 * 60 * 60 ) { return sprintf '%.1f Days', $secs / ( 24 * 60 * 60 ) }
    elsif ( $secs >= 60 * 60 ) { return sprintf '%.1f Hours', $secs / ( 60 * 60 ) }
    elsif ( $secs >= 60 ) { return sprintf '%.1f Minutes', $secs / (60) }
    else                  { return sprintf '%.1f Seconds', $secs }
}

sub connect_to_db {
    my $dbh = DBI->connect( $cfg->db_dsn, $cfg->db_user, $cfg->db_pass,
        { HandleError => sub { $log->ERR( $_[0] ); exit(1) } } );
    $dbh->{TraceLevel} = $options->{dbi_debug};
    return $dbh;
}

# Create hash with pairs of name => value for every row read from settings table
sub read_settings_from_db {
    my %settings;
    my $sth = $dbh->prepare("SELECT name, value FROM settings");
    $sth->execute();
    while ( my $r = $sth->fetchrow_arrayref ) {
        $settings{ $r->[0] } = $r->[1];
    }
    $settings{SNARE} = 0 if $settings{SNARE} != 1;
    return \%settings;
}

sub setup_log {
    my $log_dir = $settings->{PATH_LOGS};

    # Create log dir, and build log path if not provided by command line option
    if ( !-d $log_dir ) {
        mkdir( $log_dir, 0755 ) or croak("mkdir $log_dir: $!");
    }
    if ( !$options->{log_file} ) {
        $options->{log_file} = $log_dir . "/" . basename( $0, '.pl' ) . '.log';
    }

    my $log_options = {};

    # Set up output to file or both file and stderr
    if ( $options->{verbose} ) {

        # make multiplexer FH sending data both to file and STDERR
        open( my $fh, '>>:tee', $options->{log_file}, \*STDERR )
          or croak("$options->{log_file}: $!");
        $fh->autoflush(1);
        $log_options->{fh} = $fh;
    }
    else {
        open( my $fh, '>>', $options->{log_file} ) or croak("$options->{log_file}: $!");
        $log_options->{fh} = $fh;
    }

    # Setup extra information to put in every log line, depending on debug level
    if ( $options->{debug} > 1 ) {
        $log_options->{prefix} = "%D %T %S [%L] ";
    }
    else {
        $log_options->{prefix} = "%D %T [%L] ";
    }

    $log_options->{level} = $options->{debug} > 0 ? 'DEBUG' : 'INFO';

    $log->config($log_options);

    $SIG{__WARN__} = sub {
        my $msg = shift;
        $msg =~ s/\n//;
        $log->WARN($msg);
    };

    $log->INFO("Starting logging to $options->{log_file} with pid $$");
}

sub DEBUG {
    my ( $level, @log_args ) = @_;
    if ( $options->{debug} >= $level ) {
        $log->DEBUG(@log_args);
    }
}

sub cleanup_old_idx {
    $log->INFO("Starting cleanup of old index files..");
    my $basepath  = $settings->{PATH_BASE};
    my $datadir   = "$basepath/sphinx/data";
    my $retention = $settings->{RETENTION};
    DEBUG( 1, "Index Data Path is $datadir" );
    my ( $year, $mon, $day ) = ( localtime( time - ( 24 * $retention ) * 60 * 60 ) )[ 5, 4, 3 ];
    $year += 1900;
    $mon++;
    $mon = sprintf "%02d", $mon;
    $day = sprintf "%02d", $day;
    my $old_idx = 'idx_log_arch_day_' . $year . $mon . $day;
    DEBUG( 1, "DB Retention level set to $retention days" );
    DEBUG( 1, "Oldest index is $old_idx" );
    $log->INFO("Removing indexes older than $retention days");
    DEBUG( 1, "Running system command: for file in `find $datadir/idx_log_arch_day_* -type f -mtime +$retention 2>/dev/null`; do echo \"removing \$file\"; rm \$file; done" );
    system("for file in `find $datadir/idx_log_arch_day_* -type f -mtime +$retention 2>/dev/null`; do echo \"removing \$file\"; rm \$file; done") unless $options->{dryrun};

    # cleanup old indexes from views
    my @views;
    $log->INFO("Pruning old archive views");
    $sql = "SELECT table_name from information_schema.views where table_name like 'log_arch_day_%'";
    $sth_syslog = $dbh->prepare($sql);
    DEBUG( 1, "Executing SQL Statement: $sql" );
    $sth_syslog->execute();
    if ( $sth_syslog->rows > 0 ) {

        while ( $results = $sth_syslog->fetchrow_hashref ) {
            my ( undef, undef, undef, $yymmdd ) = split( /_/, $results->{'table_name'} );
            my $date = today();
            my $diff = today() - date($yymmdd);
            DEBUG( 1, "Date = $date, Diff = $diff day(s)" );
            if ( $diff > $retention ) {
                $log->INFO("Adding view $results->{'table_name'} as drop candidate because it is older than $retention days");
                push( @views, $results->{'table_name'} );
            }
        }
        if (@views) {
            foreach my $view (@views) {
                $log->INFO("Dropping view: $view");
                $sql        = "drop view $view";
                $sth_syslog = $dbh->prepare($sql);
                DEBUG( 1, "Executing SQL Statement: $sql" );
                $sth_syslog->execute() unless $options->{dryrun};
            }
        } else {
            $log->INFO("No old views found");
        }
    } else {
        $log->INFO("No old views left for cleanup");
    }
}

sub idx_rotate {
    $log->INFO("-=Analyzing Index Archives=-");
    my ( $speed, $events );
    my $memdays = $settings->{SPX_IDX_DIM};
    my $php     = `which php`;
    chomp $php;
    DEBUG( 1, "Running $php $ROOT_DIR/sphinx/sphinx.conf | grep \"^index idx_log_arch_day\" | awk '{print \$2}' | awk -F'_' '{print \$5\"_\"\$6 }' | uniq" );
    my @list = `$php $ROOT_DIR/sphinx/sphinx.conf | grep "^index idx_log_arch_day" | awk '{print \$2}' | awk -F'_' '{print \$5"_"\$6}' | uniq`;
    my @indexlist;

    foreach (@list) {
        my ( $day, $part ) = split /_/, $_;
        chomp( $day, $part );
        next if $day !~ /\d+/;
        next if $part !~ /\d+/;
        $log->INFO("Checking Index ($day, part $part)");
        DEBUG( 1, "Running command: $ROOT_DIR/sphinx/bin/indextool --config $ROOT_DIR/sphinx/sphinx.conf --dumpheader idx_log_arch_day_${day}_$part | grep docinfo | awk '{print \$2}'" );
        my $docinfo = `$ROOT_DIR/sphinx/bin/indextool --config $ROOT_DIR/sphinx/sphinx.conf --dumpheader idx_log_arch_day_${day}_$part | grep docinfo | awk '{print \$2}'`;
        chomp($docinfo);

        if ($docinfo) {
            DEBUG( 1, "Docinfo is $docinfo" );
            DEBUG( 1, "Running command: $ROOT_DIR/sphinx/bin/indextool --config $ROOT_DIR/sphinx/sphinx.conf --dumpheader idx_log_arch_day_${day}_0 | grep total-documents | awk '{print \$2}'" ) if ( !$events );
            $events = `$ROOT_DIR/sphinx/bin/indextool --config $ROOT_DIR/sphinx/sphinx.conf --dumpheader idx_log_arch_day_${day}_0 | grep total-documents | awk '{print \$2}'` if ( !$events );
            chomp($events);
            my $date = today();
            my $diff = today() - date($day);

            if ( ( $diff > $memdays ) && ( $docinfo =~ /extern/ ) ) {
                $log->INFO("The $day index is $diff day(s) older than today.");
                $log->INFO("Converting index (${day}_$part) to disk-based storage because it is > $memdays day(s) old...");
                push( @indexlist, "idx_log_arch_day_${day}_$part" );
            }

# cdukes: added below in case someone changes their idx_mem_days in teh db and we need to go back and convert disk based indexes back to memory based
            if ( ( $diff < $memdays ) && ( $docinfo =~ /inline/ ) ) {
                $log->INFO("The $day index is $diff day(s) older than today.");
                $log->INFO("Converting index (${day}_$part) to memory-based storage because it is < $memdays day(s) old and your SPX_IDX_DIM is set to $memdays");
                push( @indexlist, "idx_log_arch_day_${day}_$part" );
            }
        } else {
            $log->ERR( "Unable to obtain DOCINFO from the index header for idx_log_arch_day_${day}_$part, you will need to manually run '%s' to find out why", "$ROOT_DIR/sphinx/bin/indextool --config $ROOT_DIR/sphinx/sphinx.conf --dumpheader idx_log_arch_day_${day}_$part" );
        }
    }
    if (@indexlist) {

        # guess at sphinx's indexing speed on this server
        $speed = 12000;
        my $idxcnt = sprintf( "%.0f", scalar(@indexlist) );
        my $secs   = sprintf( "%.0f", $events / $speed * $idxcnt );
        DEBUG( 1, "events = $events, speed = $speed, indexcount = $idxcnt" );
        $log->INFO( "This may take about %s (just a non-scientific guess)", sec2human($secs) );

# cdukes: have to move this to a loop, looks like doing them all at once is too much for large scale
# instead, we will call idx_rotate every hour so that these get re-indexed one at a time
#my $indexes = join( ' ', @indexlist );
#DEBUG( 1, "Running $ROOT_DIR/sphinx/bin/indexer --config $ROOT_DIR/sphinx/sphinx.conf $indexes --rotate --sighup-each" );
#system("$ROOT_DIR/sphinx/bin/indexer --config $ROOT_DIR/sphinx/sphinx.conf $indexes --rotate --sighup-each") unless $options->{dryrun};
        foreach my $index (@indexlist) {
            DEBUG( 1, "Running $ROOT_DIR/sphinx/bin/indexer --config $ROOT_DIR/sphinx/sphinx.conf $index --rotate" );
            system("$ROOT_DIR/sphinx/bin/indexer --config $ROOT_DIR/sphinx/sphinx.conf $index --rotate") unless $options->{dryrun};
        }
    }
    $log->INFO("Completed index checks");

}

sub ss {
    $log->INFO("-=Analyzing LogZilla Server Stats=-");
    $sql = "SELECT AVG(ROUND(count)) as avg, count(*) as samples FROM events_per_second";
    $sth_syslog = $dbh->prepare($sql);
    DEBUG( 1, "Executing SQL Statement: $sql" );
    $sth_syslog->execute();
    $results = $sth_syslog->fetchrow_hashref;
    my ($eps, $eph, $epd);

    if ( ( $results->{'avg'} ) > 1 ) {

        #---
        # Memory Stats
        #---
        $log->INFO("Memory Stats...");
        my $spmem = `(cd $ROOT_DIR/sphinx/data && du -hsck *.spa *.spe *.sph *.spi *.spk *.spl *.spm *.sps | grep total | awk '{print \$1}')`;
        chomp($spmem);
        DEBUG( 1, "spmem = %s", $spmem );
        $results->{avg} = sprintf( "%0.f", $results->{avg} );
        $log->INFO( "Your current EPS average is %s (%s samples)", commify( $results->{avg} ), commify( $results->{samples} ) );
        store_metric( "lztool_eps_avg",         $results->{avg} );
        store_metric( "lztool_eps_avg_samples", $results->{samples} );
        $eps = $results->{avg};
        $eph = $results->{avg} * 60 * 60;
        $epd = $results->{avg} * 60 * 60 * 24;
        my $attrs = `cat $ROOT_DIR/sphinx/sphinx.conf | grep sql_attr | grep -v "#" | wc -l`;

        $sql        = "SELECT count(*) AS count FROM events_per_hour";
        $sth_syslog = $dbh->prepare($sql);
        DEBUG( 1, "Executing SQL Statement: $sql" );
        $sth_syslog->execute();
        $results = $sth_syslog->fetchrow_hashref;
        if ( ( $results->{'count'} ) > 1 ) {
            $log->INFO( "LogZilla uptime is %s hours", $results->{count} );
            store_metric( "lztool_srv_uptime_hours", $results->{count} );
        } else {
            $log->INFO("Sorry, there's no data available yet. Is this a new installation?");
            exit;
        }
        my $multiplier = $settings->{SPX_IDX_DIM} + 2;  # needed for current day
        # Search-time memory requirements for extern storage are (1+number_of_attrs)*number_of_docs*4 bytes, ie. 10 million docs with 2 groups and 1 timestamp will take (1+2+1)*10M*4 = 160 MB of RAM. This is PER DAEMON, ie. searchd will alloc 160 MB on startup, read the data and keep it shared between queries; the children will NOT allocate additional copies of this data.
        my $count = 0;
        my $tmp = $dbh_sphinx->do('SELECT * from idx_inmem limit 1');
        my $spx_meta  = $dbh_sphinx->prepare('show meta');
        $spx_meta->execute();
        while ( $results = $spx_meta->fetchrow_hashref ) {
            if ( $results->{'Variable_name'} eq "total_found" ) {
                $count = $results->{'Value'};
            }
        }
        chomp ($attrs);
        my $needed = ((( 3 + $attrs ) * ($count * 4  / 1000)) * $multiplier);
        DEBUG( 1, "(1 + %s Attributes) * %s Messages in idx_inmem * 4 = $needed", $attrs, $count);
        $log->INFO( "Expecting %s average EPD", commify($epd) );
        store_metric( "lztool_epd", $epd );
        my $total = `cat /proc/meminfo | grep MemTotal | awk '{print \$2}'`;
        chomp($total);
        my $free = `cat /proc/meminfo | grep MemFree | awk '{print \$2}'`;
        chomp($free);
        $log->INFO( "You have %s total system memory", humanBytes($total) );
        $log->INFO( "You have %s free system memory",  humanBytes($free) );
        $log->INFO( "Your server is configured to store %d extra day(s) of events in memory (the rest on disk)", $settings->{SPX_IDX_DIM} );
        $log->INFO( "The LogZilla indexer is using %s RAM to store indexed information in memory - note that this is only for the indexer and not for system resources or MySQL", humanBytes($spmem) );
        #$log->INFO( "LogZilla is currently using %s of that %s total.", humanBytes($spmem), humanBytes($needed) );
        store_metric( "lztool_idx_memused", $spmem );
        store_metric( "lztool_mem_total",   $total );
        store_metric( "lztool_mem_free",    $free );
        store_metric( "lztool_spx_dim",     $settings->{SPX_IDX_DIM} );
        store_metric( "lztool_mem_needed",  $needed );
        my $remainder = $free - ( $needed - $spmem );

        if ( ($remainder) < 0 ) {
            $remainder = -$remainder;
            $log->WARN("You don't have enough memory to support this logging level!");
            $log->INFO( "You need at least %s more Ram", humanBytes($remainder) );
        }

        #---
        # Disk Stats
        #---
        $log->INFO("Disk Stats...");
        my $dbsize_kbytes = 0;
        my $spdsk = `(cd $ROOT_DIR/sphinx/data && du -hsck *.spd *.spe *.sph *.spi *.spk *.spl *.spm *.spp *.sps | grep total | awk '{print \$1}')`;
        chomp($spdsk);
        my $du = $spdsk; # define du here in case the only disk usage is from today (server only up for one day)
        $log->INFO( "Current Index Size (on disk) is approximately %s", humanBytes($spdsk) );
        store_metric( "lztool_index_diskused_KB", $spdsk );
        $sql = "SELECT table_schema, Round(Sum(data_length + index_length) / 1024, 0) AS 'dbsize_kbytes' FROM information_schema.tables WHERE table_schema='syslog' GROUP  BY table_schema";
        $sth_syslog = $dbh->prepare($sql);
        DEBUG( 1, "Executing SQL Statement: $sql" );
        $sth_syslog->execute();
        $results = $sth_syslog->fetchrow_hashref;
        $dbsize_kbytes = $results->{'dbsize_kbytes'};
        $log->INFO( "Current DB size (on disk) is approximately %s", humanBytes( $dbsize_kbytes ) );
        store_metric( "lztool_db_diskused_KB", $dbsize_kbytes );

# below doesn't work because events/sec don't drop for data > $retention
# $sql = "SELECT FROM_UNIXTIME(ts_from) as dt, ts_from AS ts FROM events_per_second limit 1";
        $sql = "SELECT UNIX_TIMESTAMP(fo) AS ts, fo AS dt FROM logs ORDER BY lo ASC LIMIT 1";
        $sql = "SELECT (SELECT UNIX_TIMESTAMP(max(lo)) from logs) as ts, (SELECT min(fo) from logs) as fo, (SELECT max(lo) from logs) as lo";
        $sth_syslog = $dbh->prepare($sql);
        DEBUG( 1, "Executing SQL Statement: $sql" );
        $sth_syslog->execute();
        $results = $sth_syslog->fetchrow_hashref;
        my $db_numdays = 0;

        if ( ( $results->{'ts'} ) > 1 ) {
            my $date = today();
            my ( $ymd, undef ) = split( /\s+/, $results->{fo} );
            $db_numdays = today() - date($ymd) + 1; # Note: add +1 here to include today in the disk usage calculation
            DEBUG( 1, "YMD = %s, DB->fo = %s, DB->lo = %s, DB->ts = %s, Date = %s, Diff = %s", $ymd, $results->{fo}, $results->{lo}, $results->{ts}, $date, $db_numdays );
            if ( $db_numdays < 2 ) {
                $log->WARN("Results may not be accurate, please run this tool after your server has been running for > 2 days");
            }
            $du = sprintf( "%d", ( $spdsk / $db_numdays ) );
            DEBUG( 1, "spdisk = %s, db_numdays = %s, du = %s", $spdsk, $db_numdays, $du );
            $log->INFO( "LogZilla indexes (excluding MySQL) should consume about %s of disk per day.", humanBytes($du) );
            $log->INFO( "MySQL should consume about %s of disk per day.", humanBytes($dbsize_kbytes / $db_numdays) );
            store_metric( "lztool_estimated_disk_perday", "$du" );
        }

        #---
        # MySQL Helper
        #---
        if ( $options->{mysql} ) {
            $log->INFO("MySQL Analysis...");
            $sql = "SELECT CONCAT(ROUND(KBS/POWER(1024,IF(pw<0,0,IF(pw>3,0,pw)))+0.49999), SUBSTR(' KMG',IF(pw<0,0,IF(pw>3,0,pw))+1,1)) recommended_innodb_buffer_pool_size FROM (SELECT SUM(index_length) KBS FROM information_schema.tables WHERE engine='InnoDB') A,(SELECT 3 pw) B;";
            $sth_syslog = $dbh->prepare($sql);
            DEBUG( 1, "Executing SQL Statement: $sql" );
            $sth_syslog->execute();
            $results = $sth_syslog->fetchrow_hashref;
            my $recommended_innodb_buffer_pool_size = $results->{'recommended_innodb_buffer_pool_size'};
            $sql = "SELECT CONCAT(ROUND(KBS/POWER(1024,IF(pw<0,0,IF(pw>3,0,pw)))+0.49999), SUBSTR(' KMG',IF(pw<0,0,IF(pw>3,0,pw))+1,1)) recommended_key_buffer_size FROM (SELECT SUM(index_length) KBS FROM information_schema.tables WHERE engine='MyISAM' AND table_schema NOT IN ('information_schema','mysql')) A, (SELECT 3 pw) B";
            $sth_syslog = $dbh->prepare($sql);
            DEBUG( 1, "Executing SQL Statement: $sql" );
            $sth_syslog->execute();
            $results = $sth_syslog->fetchrow_hashref;
            my $recommended_key_buffer_size = $results->{'recommended_key_buffer_size'};
            $log->INFO( "The recommended innodb_buffer_pool_size for this server is %s", $recommended_innodb_buffer_pool_size );
            $log->INFO( "The recommended key_buffer_size for this server is %s", $recommended_key_buffer_size );
            store_metric( "lztool_innodb_rec", HumanToBytes("$recommended_innodb_buffer_pool_size") );
            store_metric( "lztool_myisam_rec", HumanToBytes("$recommended_key_buffer_size") );
        }
    } else {
        $log->INFO("Sorry, there's no EPS data avilable yet. Is this a new installation?");
    }
}

sub mtti {
    $log->INFO("-=Calculating MTTI Stats=-");
    $sql = "SELECT FROM_UNIXTIME(ts_start) AS start, FROM_UNIXTIME(ts_end) AS end, value FROM sph_metrics WHERE name='indexer'";
    $sth_syslog = $dbh->prepare($sql);
    DEBUG( 1, "Executing SQL Statement: $sql" );
    $sth_syslog->execute();
    my @vals;
    while ( $results = $sth_syslog->fetchrow_hashref ) {
        my $diff = str2time( $results->{end} ) - str2time( $results->{start} );
        DEBUG( 1, "diff between %s and %s is %s", $results->{start}, $results->{end}, sec2human($diff) );
        push( @vals, $results->{value} );
    }
    if (@vals) {
        my $int = sprintf "%d", mean(@vals);
        $log->INFO( "Mean Time To Index is %d seconds (%s samples)", $int, commify( scalar(@vals) ) );
        store_metric( "lztool_mtti", $int );
    } else {
        $log->INFO("Sorry, there's no data available yet. Is this a new installation?");
    }
}

sub store_metric {
    my ( $name, $value ) = @_;

    #$log->INFO("Storing Metrics: $name = $value");
    DEBUG( 1, "Storing Metrics: $name = $value" );
    $sql = "INSERT INTO sph_metrics (name,value,ts_start,ts_end) VALUES ('$name', $value, UNIX_TIMESTAMP(NOW()), UNIX_TIMESTAMP(NOW()))";
    DEBUG( 1, "Executing SQL Statement: $sql" );
    $dbh->do($sql) unless $options->{dryrun};
}

sub waitfor {

    # Need to wait for indexer to finish if it is restarting searchd
    my ( $proc, $sleepfor, $timelimit ) = @_;
    my $i = 0;
    DEBUG( 1, "Running ps -C $proc -o pid=" );
    my $pid = `ps -C $proc -o pid=`;
    DEBUG( 1, "PID = $pid" );
    while ($pid) {
        chomp $pid;
        $log->INFO("$0: Waiting up to $timelimit seconds for $proc on PID $pid to finish...");
        if ( $i >= $timelimit ) {
            $log->INFO("$0: Timed out waiting for $proc on PID $pid");
            exit;
        }
        sleep $sleepfor;
        $pid = `ps -C $proc -o pid=`;
        $i += $sleepfor;
    }
}

sub makeview {
    my $ymd = $options->{mvdate};
    my ( $y, $m, $d );
    if ($ymd) {
        if ( $ymd =~ /(\d{4})-?(\d{2})-?(\d{2})-?/ ) {
            my $y = $1;
            my $m = $2;
            my $d = $3;
            $log->INFO("Creating view name log_arch_day_$y$m$d");
            $sql = "CREATE OR REPLACE VIEW log_arch_day_$y$m$d AS SELECT `logs`.`id` AS `id`,`logs`.`host` AS `host`,`logs`.`facility` AS `facility`,`logs`.`severity` AS `severity`,`logs`.`program` AS `program`,`logs`.`msg` AS `msg`,`logs`.`mne` AS `mne`,`logs`.`eid` AS `eid`,`logs`.`suppress` AS `suppress`,`logs`.`counter` AS `counter`,`logs`.`fo` AS `fo`,`logs`.`lo` AS `lo`,`logs`.`notes` AS `notes` FROM `logs` where ((`logs`.`fo` >= '$ymd 00:00:00') AND (`logs`.`fo` <= '$ymd 23:59:59'))";
            DEBUG( 1, "Executing SQL Statement: $sql" );
            $dbh->do($sql) unless $options->{dryrun};
            $sql = "SELECT table_name FROM INFORMATION_SCHEMA.tables where table_type = 'VIEW' AND table_schema = 'syslog' AND table_name LIKE 'log_arch_day_$y$m$d%'";
            $sth_syslog = $dbh->prepare($sql);
            DEBUG( 1, "Executing SQL Statement: $sql" );
            $sth_syslog->execute();

            while ( $results = $sth_syslog->fetchrow_hashref ) {
                $log->INFO("Creating view_limits for log_arch_day_$y$m$d");
                $sql = "REPLACE INTO view_limits (view_name, min_id, max_id) values ('$results->{table_name}', (SELECT min(id) FROM $results->{table_name}), (SELECT max(id) FROM $results->{table_name}))";
                DEBUG( 1, "Executing SQL Statement: $sql" );
                $dbh->do($sql) unless $options->{dryrun};
                $log->INFO("View creation complete");
                unless ( $options->{yes} ) {
                    my $ok = &getYN( "Data will be unavailable until indexed. Should I index the new data?", "y" );
                    if ( $ok =~ /[Yy]/ ) {
                        my $cores = $settings->{SPX_CPU_CORES};
                        for ( my $i = 0 ; $i < $cores ; $i++ ) {
                            system("cd $ROOT_DIR/sphinx && bin/indexer  idx_log_arch_day_$y$m${d}_$i --rotate");
                        }
                    }
                } else {
                    my $cores = $settings->{SPX_CPU_CORES};
                    for ( my $i = 0 ; $i < $cores ; $i++ ) {
                        system("cd $ROOT_DIR/sphinx && bin/indexer  idx_log_arch_day_$y$m${d}_$i --rotate");
                    }
                }
            }
        } else {
            $log->ERR("Option -mvdate must be in the form YYYY-MM-DD");
        }
    } else {
        $log->ERR("Option 'makeview' requires a date in the form YYYY-MM-DD");
    }
}
